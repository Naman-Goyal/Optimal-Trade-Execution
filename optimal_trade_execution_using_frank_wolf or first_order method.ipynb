{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a first-order (Frank-Wolfe) algorithm for the optimal execution problem, using Gurobi as the LP solver.  Feel free to reuse the code that I have uploaded.  Compare with they Python code that you wrote.\n",
    "As before, your code should take as input the values $\\alpha$, $\\pi$, $N$ (number of shares to sell) and $T$ (number of periods available).  It should output the optimal execution in each period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "#from gurobipy import *\n",
    "import numpy as np\n",
    "from sympy import symbols, diff\n",
    "from scipy.optimize import check_grad\n",
    "\n",
    "def mif(x,alpha,pi):\n",
    "    mi = (1-alpha*x**pi)\n",
    "    return mi\n",
    "\n",
    "def myfunction(x):\n",
    "    mi=mif(x,alpha,pi)\n",
    "    multi = np.cumprod(mi)\n",
    "    revenue = np.sum(x*multi)\n",
    "    return revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function return the objective. For a vector $x$ where $x[i]$ represents the number of shares sell at time i, the objective is given by:\n",
    "$$obj(x) = \\sum_{i=1}^T x_i\\Pi_{j=1}^i f(x_j)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This grad_sub fucntion computes the gradient of the objective function at a vector x.\n",
    "def grad_sub(x):\n",
    "    gradient = np.zeros(len(x))\n",
    "    fx =mif(np.array(x),alpha,pi)\n",
    "    cum_f = np.cumprod(fx)\n",
    "\n",
    "    fx_decal = np.array([1]+list(fx[:(len(x)-1)]))\n",
    "    \n",
    "    fdec_cum = np.cumprod(fx_decal)\n",
    "    \n",
    "    matrix_f =  np.triu(np.array([fx,]*len(x))) + np.tril(np.ones((len(x),len(x))),-1)\n",
    "    \n",
    "    matrix_cum_f = np.cumprod(matrix_f,axis=1)\n",
    "    \n",
    "    for i in range(len(x)-1):\n",
    "        if (x[i] == 0):\n",
    "            #When x[i] = 0, gradient[i] is not define so we set it arbitrarly to a big number.\n",
    "            gradient[i] = -100000\n",
    "        else:\n",
    "            gradient[i] = fdec_cum[i]*(1 - alpha*(pi+1)*(x[i]**pi) - alpha*pi*(x[i]**(pi-1))*np.sum(x[(i+1):]*matrix_cum_f[(i+1),(i+1):]))\n",
    "    gradient[len(x)-1] = np.prod(fx[:(len(x)-1)])*(1 - alpha*(pi+1)*(x[len(x)-1]**(pi)))\n",
    "    \n",
    "    return gradient\n",
    "\n",
    "def gradcomp1(n, x):  \n",
    "    gradient = grad_sub(x)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Optimal execution algorithm\n",
    "In this algorithm, we find the optimal execution with a first-order method. That is to say, we iterate on the following:\n",
    " 1. Compute gradient at current point\n",
    " 2. Compute slacks at current point\n",
    " 3. Set up step computation LP\n",
    " 4. Solve LP\n",
    " 5. Get solution\n",
    " 6. Step-size computation\n",
    " 7. Move to new point\n",
    "We can compute the gradient and the slacks at the current point with the functions we previously define.\n",
    "With the function steplp that uses Gurobi, we set up and solve the LP to move to a new point that increases the obj. \n",
    "Finally, we use the function loop to perform those operations several times.\n",
    "\n",
    "The function steplp has the follwing inputs:\n",
    "\n",
    "t, which represents the numer of dates at which we can trade shares.\n",
    "x, which is our current trading schedule i.e. x[i] is how many shares we are selling at time i.\n",
    "slacks, which is a vector which size is the number of constraints that are inequalities. \n",
    "In out problem slak is equal to x because we only have the constraints ð‘¥ð‘–â‰¥0\n",
    "gradient which is the gradient of the objective function at point x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_slacks(x,N):\n",
    "    lslacks = -x\n",
    "    uslacks = N-x\n",
    "    return lslacks, uslacks\n",
    "\n",
    "def steplp(T, x):\n",
    "    m = Model(\"feasible\")\n",
    "    m.ModelSense = -1 #maximize\n",
    "    \n",
    "    gradient = gradcomp1 (T,x)\n",
    "    #create variables and put into a dictionary\n",
    "    deltavar = {}\n",
    "    for j in range(T):\n",
    "        deltavar[j] = m.addVar(lb = -1.0, ub = 1.0, obj = gradient[j], vtype = GRB.CONTINUOUS, name = \"delta_\"+str(j+1))\n",
    "\n",
    "    # Update model to integrate new variables\n",
    "    m.update()\n",
    "    #add first constraint\n",
    "    xpr = LinExpr()\n",
    "    for i in range(T):\n",
    "        xpr += deltavar[i]\n",
    "    m.addConstr(xpr == 0, name=\"const1\")\n",
    "    \n",
    "    #add constraint\n",
    "    lslacks, uslacks = compute_slacks(x,N)\n",
    "    for j in range(T):\n",
    "        m.addConstr(deltavar[j]-lslacks[j] >= 0 , name=\"constl\"+str(j+1))\n",
    "        m.addConstr(deltavar[j]-uslacks[j] <= 0 , name=\"constu\"+str(j+1))\n",
    "    \n",
    "    m.update()\n",
    "    m.optimize()\n",
    "    \n",
    "    code = \"optimal\"\n",
    "\n",
    "    if m.status == GRB.status.INF_OR_UNBD:\n",
    "        print('->LP infeasible or unbounded\\n')\n",
    "        code = \"inf_or_unbd\"\n",
    "    if m.status == GRB.status.UNBOUNDED:\n",
    "        print('->LP unbounded\\n')\n",
    "        code = \"unbd\"\n",
    "    if m.status == GRB.status.INFEASIBLE:\n",
    "        print('->LP infeasible\\n')\n",
    "        code = \"infeasible\"\n",
    "\n",
    "\n",
    "    deltasol = np.zeros(T)\n",
    "    for j in range(T):\n",
    "        deltasol[j] = deltavar[j].x\n",
    "\n",
    "    return deltasol, code==\"optimal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.f Step-size computation\n",
    "def linesearch(x,deltasol,Size=100):\n",
    "    #h/Size is stepsize\n",
    "    h=np.arange(Size+1)\n",
    "    val=np.zeros(Size+1)\n",
    "    for i in h:\n",
    "        val[i] = myfunction(x+(h[i]/Size)*deltasol)\n",
    "    print(val)\n",
    "    h_opt=np.argmax(val)/Size\n",
    "    return h_opt\n",
    "\n",
    "#2. Iterate\n",
    "def loop(T,x,deltasol,deltabool,h_opt,stop_dif=0.001):\n",
    "    \n",
    "    if deltabool==True:\n",
    "        #2.g Move to new point\n",
    "        x_1=x+h_opt*deltasol\n",
    "        if np.nonzero(deltasol)==True:\n",
    "            val=myfunction(x)\n",
    "            return x,val\n",
    "        elif myfunction(x_1)<myfunction(x):\n",
    "            print('the objective value decreases after the movement')\n",
    "            val=myfunction(x)\n",
    "            return x,val\n",
    "        elif myfunction(x_1)-myfunction(x)<stop_dif:\n",
    "            val=myfunction(x_1)\n",
    "            return x_1,val\n",
    "        else:\n",
    "            x=x_1\n",
    "#             print(x)\n",
    "            deltasol,deltabool=steplp(T, x)\n",
    "            h_opt=linesearch(x,deltasol,Size=100)\n",
    "            return loop(T,x,deltasol,deltabool,h_opt,stop_dif=0.001)\n",
    "    else:\n",
    "        print('cannot find a direction of movement')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(a,b,c,d):\n",
    "    global alpha,pi,N,T\n",
    "    alpha,pi,N,T = a,b,c,d\n",
    "    \n",
    "    gradient = np.empty(T)\n",
    "    print(gradient)\n",
    "    x = np.repeat(N/T,T)\n",
    "    gradient =  gradcomp1(T, x)\n",
    "    print(gradient)\n",
    "    deltasol, deltabool = steplp(T, x)\n",
    "    print(deltasol)\n",
    "    h_opt = linesearch(x,deltasol)\n",
    "    print(h_opt)\n",
    "    x,val = loop(T,x,deltasol,deltabool,h_opt,stop_dif=0.001)\n",
    "    \n",
    "    return x, val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99560491 0.99427621 0.99294948 0.99162471 0.99030191 0.98898105\n",
      " 0.98766215 0.9863452  0.9850302  0.98371714 0.98240603 0.98109685\n",
      " 0.97978961 0.9784843  0.97718092 0.97587947 0.97457995 0.97328234\n",
      " 0.97198666 0.97069289]\n",
      "[0.99560491 0.99427621 0.99294948 0.99162471 0.99030191 0.98898105\n",
      " 0.98766215 0.9863452  0.9850302  0.98371714 0.98240603 0.98109685\n",
      " 0.97978961 0.9784843  0.97718092 0.97587947 0.97457995 0.97328234\n",
      " 0.97198666 0.97069289]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-1e551c0d0cc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-42-fa88dcd1a66b>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(a, b, c, d)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mgradcomp1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mdeltasol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeltabool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteplp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeltasol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mh_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinesearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdeltasol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-7f803c7bd62b>\u001b[0m in \u001b[0;36msteplp\u001b[1;34m(T, x)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msteplp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"feasible\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelSense\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;31m#maximize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "run(0.001,0.1,1000,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
